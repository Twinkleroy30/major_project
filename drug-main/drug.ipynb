{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset generated successfully!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Generate synthetic dataset\n",
        "num_samples = 1000\n",
        "\n",
        "# Patient Information\n",
        "patient_ids = [f\"P{str(i).zfill(5)}\" for i in range(1, num_samples + 1)]\n",
        "ages = np.random.randint(18, 90, num_samples)\n",
        "genders = np.random.choice([\"Male\", \"Female\"], num_samples)\n",
        "medical_history = np.random.choice([\"Diabetes\", \"Hypertension\", \"Cancer\", \"None\"], num_samples)\n",
        "\n",
        "drug_names = np.random.choice([\"DrugA\", \"DrugB\", \"DrugC\", \"DrugD\"], num_samples)\n",
        "dosages = np.random.randint(50, 500, num_samples)\n",
        "treatment_durations = np.random.randint(5, 60, num_samples)\n",
        "effectiveness = np.random.uniform(0, 100, num_samples)\n",
        "side_effects = np.random.choice([\"None\", \"Nausea\", \"Dizziness\", \"Fatigue\"], num_samples)\n",
        "\n",
        "disease_types = np.random.choice([\"Lung Cancer\", \"Breast Cancer\", \"Diabetes\", \"Heart Disease\"], num_samples)\n",
        "genetic_markers = np.random.choice([\"MarkerA\", \"MarkerB\", \"MarkerC\", \"MarkerD\"], num_samples)\n",
        "\n",
        "# Treatment Outcome\n",
        "response_to_treatment = np.random.choice([\"Positive\", \"Negative\"], num_samples)\n",
        "success_rates = np.random.uniform(50, 100, num_samples)\n",
        "\n",
        "# Create DataFrame\n",
        "dataset = pd.DataFrame({\n",
        "    \"Patient_ID\": patient_ids,\n",
        "    \"Age\": ages,\n",
        "    \"Gender\": genders,\n",
        "    \"Medical_History\": medical_history,\n",
        "    \"Drug_Name\": drug_names,\n",
        "    \"Dosage_mg\": dosages,\n",
        "    \"Treatment_Duration_days\": treatment_durations,\n",
        "    \"Effectiveness_%\": effectiveness,\n",
        "    \"Side_Effects\": side_effects,\n",
        "    \"Disease_Type\": disease_types,\n",
        "    \"Genetic_Marker\": genetic_markers,\n",
        "    \"Response_to_Treatment\": response_to_treatment,\n",
        "    \"Success_Rate_%\": success_rates\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "dataset.to_csv(\"synthetic_medical_dataset.csv\", index=False)\n",
        "\n",
        "print(\"Dataset generated successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "25/25 [==============================] - 2s 14ms/step - loss: 0.8743 - accuracy: 0.5288 - val_loss: 0.6944 - val_accuracy: 0.4700\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.8814 - accuracy: 0.4875 - val_loss: 0.6975 - val_accuracy: 0.4900\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.8022 - accuracy: 0.5437 - val_loss: 0.7009 - val_accuracy: 0.4950\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.7828 - accuracy: 0.5587 - val_loss: 0.7071 - val_accuracy: 0.4300\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.7092 - accuracy: 0.5987 - val_loss: 0.7082 - val_accuracy: 0.4600\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.7139 - accuracy: 0.5838 - val_loss: 0.7073 - val_accuracy: 0.4850\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.7300 - accuracy: 0.5600 - val_loss: 0.7059 - val_accuracy: 0.5100\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.6855 - accuracy: 0.6200 - val_loss: 0.7064 - val_accuracy: 0.5100\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.6955 - accuracy: 0.6000 - val_loss: 0.7117 - val_accuracy: 0.5050\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.6847 - accuracy: 0.5850 - val_loss: 0.7174 - val_accuracy: 0.5000\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6707 - accuracy: 0.6200 - val_loss: 0.7300 - val_accuracy: 0.4750\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.6595 - accuracy: 0.6075 - val_loss: 0.7377 - val_accuracy: 0.4750\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.6668 - accuracy: 0.6187 - val_loss: 0.7358 - val_accuracy: 0.4550\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.6534 - accuracy: 0.6463 - val_loss: 0.7374 - val_accuracy: 0.4600\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6362 - accuracy: 0.6463 - val_loss: 0.7440 - val_accuracy: 0.4850\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6516 - accuracy: 0.6162 - val_loss: 0.7554 - val_accuracy: 0.4650\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6292 - accuracy: 0.6363 - val_loss: 0.7651 - val_accuracy: 0.4850\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.6280 - accuracy: 0.6600 - val_loss: 0.7672 - val_accuracy: 0.4850\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6316 - accuracy: 0.6413 - val_loss: 0.7740 - val_accuracy: 0.5000\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6186 - accuracy: 0.6488 - val_loss: 0.7870 - val_accuracy: 0.5000\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6393 - accuracy: 0.6363 - val_loss: 0.7807 - val_accuracy: 0.4500\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.5969 - accuracy: 0.6938 - val_loss: 0.7921 - val_accuracy: 0.4400\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6042 - accuracy: 0.6737 - val_loss: 0.8047 - val_accuracy: 0.4550\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6308 - accuracy: 0.6325 - val_loss: 0.8145 - val_accuracy: 0.4550\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6157 - accuracy: 0.6675 - val_loss: 0.8130 - val_accuracy: 0.4900\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.5826 - accuracy: 0.6700 - val_loss: 0.8228 - val_accuracy: 0.4900\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.6200 - accuracy: 0.6463 - val_loss: 0.8305 - val_accuracy: 0.4750\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6020 - accuracy: 0.6662 - val_loss: 0.8407 - val_accuracy: 0.4950\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.5772 - accuracy: 0.7038 - val_loss: 0.8408 - val_accuracy: 0.4850\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.5770 - accuracy: 0.6988 - val_loss: 0.8590 - val_accuracy: 0.4900\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.8590 - accuracy: 0.4900\n",
            "Test Accuracy: 0.49\n",
            "Model saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Load dataset\n",
        "dataset = pd.read_csv(\"synthetic_medical_dataset.csv\")\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "categorical_columns = [\"Gender\", \"Medical_History\", \"Drug_Name\", \"Side_Effects\", \"Disease_Type\", \"Genetic_Marker\", \"Response_to_Treatment\"]\n",
        "\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    dataset[col] = le.fit_transform(dataset[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Selecting features and target variables\n",
        "X = dataset.drop(columns=[\"Patient_ID\", \"Response_to_Treatment\"]).values\n",
        "y = dataset[\"Response_to_Treatment\"].values\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape for CNN input (assuming 1D features per patient)\n",
        "X = np.expand_dims(X, axis=2)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X.shape[1], 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.2),\n",
        "    \n",
        "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "    \n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
        "\n",
        "# Save the model\n",
        "model.save(\"cnn_drug_discovery_model.h5\")\n",
        "print(\"Model saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully!\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 11, 1), found shape=(None, 10, 1)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m input_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(input_array, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Make prediction\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m (prediction \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_class[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mC:\\Users\\TWINKL~1\\AppData\\Local\\Temp\\__autograph_generated_filentmv2f3i.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 11, 1), found shape=(None, 10, 1)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load the trained model\n",
        "model_path = r\"cnn_drug_discovery_model.h5\"\n",
        "model = load_model(model_path)\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# Define label encoders for categorical values\n",
        "label_encoders = {\n",
        "    \"Gender\": LabelEncoder().fit([\"Male\", \"Female\"]),\n",
        "    \"Medical_History\": LabelEncoder().fit([\"Diabetes\", \"Hypertension\", \"Cancer\", \"None\"]),\n",
        "    \"Drug_Name\": LabelEncoder().fit([\"DrugA\", \"DrugB\", \"DrugC\", \"DrugD\"]),\n",
        "    \"Side_Effects\": LabelEncoder().fit([\"None\", \"Nausea\", \"Dizziness\", \"Fatigue\"]),\n",
        "    \"Disease_Type\": LabelEncoder().fit([\"Lung Cancer\", \"Breast Cancer\", \"Diabetes\", \"Heart Disease\"]),\n",
        "    \"Genetic_Marker\": LabelEncoder().fit([\"MarkerA\", \"MarkerB\", \"MarkerC\", \"MarkerD\"])\n",
        "}\n",
        "\n",
        "# Define a scaler (use values from training phase if available)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Example input values\n",
        "input_data = {\n",
        "    \"Age\": 45,\n",
        "    \"Gender\": \"Male\",\n",
        "    \"Medical_History\": \"Diabetes\",\n",
        "    \"Drug_Name\": \"DrugA\",\n",
        "    \"Dosage_mg\": 200,\n",
        "    \"Treatment_Duration_days\": 30,\n",
        "    \"Effectiveness_%\": 85.4,\n",
        "    \"Side_Effects\": \"Nausea\",\n",
        "    \"Disease_Type\": \"Lung Cancer\",\n",
        "    \"Genetic_Marker\": \"MarkerB\"\n",
        "}\n",
        "\n",
        "# Encode categorical values\n",
        "for key in label_encoders:\n",
        "    if key in input_data:\n",
        "        input_data[key] = label_encoders[key].transform([input_data[key]])[0]\n",
        "\n",
        "# Convert input data to array\n",
        "input_array = np.array(list(input_data.values())).reshape(1, -1)\n",
        "\n",
        "# Normalize input features (use values from training phase if available)\n",
        "input_array = scaler.fit_transform(input_array)  # Use transform() instead of fit_transform() if scaler was previously trained\n",
        "\n",
        "# Reshape for CNN input\n",
        "input_array = np.expand_dims(input_array, axis=2)\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(input_array)\n",
        "predicted_class = (prediction > 0.5).astype(int)\n",
        "\n",
        "print(f\"Predicted Response: {predicted_class[0][0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully!\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 11, 1), found shape=(None, 10, 1)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[31], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m input_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(input_array, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Make prediction for drug effectiveness\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m effectiveness_score \u001b[38;5;241m=\u001b[39m prediction[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m  \u001b[38;5;66;03m# Convert to percentage\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Drug Effectiveness: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meffectiveness_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mC:\\Users\\TWINKL~1\\AppData\\Local\\Temp\\__autograph_generated_filehz0tcgm1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 11, 1), found shape=(None, 10, 1)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Load the trained model\n",
        "model_path = r\"cnn_drug_discovery_model.h5\"\n",
        "model = load_model(model_path)\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# Define label encoders for categorical values\n",
        "label_encoders = {\n",
        "    \"Gender\": LabelEncoder().fit([\"Male\", \"Female\"]),\n",
        "    \"Medical_History\": LabelEncoder().fit([\"Diabetes\", \"Hypertension\", \"Cancer\", \"None\"]),\n",
        "    \"Drug_Name\": LabelEncoder().fit([\"DrugA\", \"DrugB\", \"DrugC\", \"DrugD\"]),\n",
        "    \"Side_Effects\": LabelEncoder().fit([\"None\", \"Nausea\", \"Dizziness\", \"Fatigue\"]),\n",
        "    \"Disease_Type\": LabelEncoder().fit([\"Lung Cancer\", \"Breast Cancer\", \"Diabetes\", \"Heart Disease\"]),\n",
        "    \"Genetic_Marker\": LabelEncoder().fit([\"MarkerA\", \"MarkerB\", \"MarkerC\", \"MarkerD\"])\n",
        "}\n",
        "\n",
        "# Define a scaler (use values from training phase if available)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Example input values for drug effectiveness prediction\n",
        "input_data = {\n",
        "    \"Age\": 45,\n",
        "    \"Gender\": \"Male\",\n",
        "    \"Medical_History\": \"Diabetes\",\n",
        "    \"Drug_Name\": \"DrugB\",\n",
        "    \"Dosage_mg\": 100,\n",
        "    \"Treatment_Duration_days\": 40,\n",
        "    \"Effectiveness_%\": 15.4,\n",
        "    \"Side_Effects\": \"Nausea\",\n",
        "    \"Disease_Type\": \"Lung Cancer\",\n",
        "    \"Genetic_Marker\": \"MarkerB\"\n",
        "}\n",
        "\n",
        "# Encode categorical values\n",
        "for key in label_encoders:\n",
        "    if key in input_data:\n",
        "        input_data[key] = label_encoders[key].transform([input_data[key]])[0]\n",
        "\n",
        "# Convert input data to array\n",
        "input_array = np.array(list(input_data.values())).reshape(1, -1)\n",
        "\n",
        "# Normalize input features (use values from training phase if available)\n",
        "input_array = scaler.fit_transform(input_array)  # Use transform() instead of fit_transform() if scaler was previously trained\n",
        "\n",
        "# Reshape for CNN input\n",
        "input_array = np.expand_dims(input_array, axis=2)\n",
        "\n",
        "# Make prediction for drug effectiveness\n",
        "prediction = model.predict(input_array)\n",
        "effectiveness_score = prediction[0][0] * 100  # Convert to percentage\n",
        "\n",
        "print(f\"Predicted Drug Effectiveness: {effectiveness_score:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scaler and feature names saved successfully!\n",
            "Epoch 1/30\n",
            "25/25 [==============================] - 2s 22ms/step - loss: 0.9640 - accuracy: 0.4688 - val_loss: 0.6942 - val_accuracy: 0.4850\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.8356 - accuracy: 0.5437 - val_loss: 0.6950 - val_accuracy: 0.4800\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.8186 - accuracy: 0.4988 - val_loss: 0.6950 - val_accuracy: 0.4900\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.7597 - accuracy: 0.5500 - val_loss: 0.7052 - val_accuracy: 0.5100\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.7492 - accuracy: 0.5487 - val_loss: 0.7068 - val_accuracy: 0.5050\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.7407 - accuracy: 0.5550 - val_loss: 0.7217 - val_accuracy: 0.5050\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.7206 - accuracy: 0.5625 - val_loss: 0.7317 - val_accuracy: 0.5050\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6978 - accuracy: 0.5863 - val_loss: 0.7290 - val_accuracy: 0.5050\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.6971 - accuracy: 0.5713 - val_loss: 0.7318 - val_accuracy: 0.4750\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.6937 - accuracy: 0.5750 - val_loss: 0.7229 - val_accuracy: 0.4750\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.7071 - accuracy: 0.5587 - val_loss: 0.7145 - val_accuracy: 0.5050\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.6802 - accuracy: 0.5713 - val_loss: 0.7075 - val_accuracy: 0.5200\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6974 - accuracy: 0.5487 - val_loss: 0.7023 - val_accuracy: 0.5300\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6694 - accuracy: 0.5888 - val_loss: 0.7030 - val_accuracy: 0.5250\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6831 - accuracy: 0.5763 - val_loss: 0.6939 - val_accuracy: 0.5200\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6563 - accuracy: 0.6150 - val_loss: 0.6947 - val_accuracy: 0.5350\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.5700 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.6569 - accuracy: 0.6187 - val_loss: 0.6867 - val_accuracy: 0.5500\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6509 - accuracy: 0.6237 - val_loss: 0.6925 - val_accuracy: 0.5450\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6477 - accuracy: 0.6463 - val_loss: 0.6888 - val_accuracy: 0.5450\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6424 - accuracy: 0.6237 - val_loss: 0.6931 - val_accuracy: 0.5150\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.6427 - accuracy: 0.6200 - val_loss: 0.7035 - val_accuracy: 0.5350\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.6324 - accuracy: 0.6425 - val_loss: 0.7013 - val_accuracy: 0.5150\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6405 - accuracy: 0.6350 - val_loss: 0.7069 - val_accuracy: 0.5400\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.6266 - accuracy: 0.6538 - val_loss: 0.7022 - val_accuracy: 0.5300\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.6258 - accuracy: 0.6400 - val_loss: 0.7195 - val_accuracy: 0.5300\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.6377 - accuracy: 0.6363 - val_loss: 0.7037 - val_accuracy: 0.5500\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.6101 - accuracy: 0.6450 - val_loss: 0.7132 - val_accuracy: 0.5400\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.6143 - accuracy: 0.6650 - val_loss: 0.7086 - val_accuracy: 0.5150\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.6070 - accuracy: 0.6637 - val_loss: 0.7132 - val_accuracy: 0.4950\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7132 - accuracy: 0.4950\n",
            "Test Accuracy: 0.50\n",
            "Model saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\TWINKLE ROY\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import joblib  # Import joblib for saving the scaler\n",
        "\n",
        "# Load dataset\n",
        "dataset = pd.read_csv(\"synthetic_medical_dataset.csv\")\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoders = {}\n",
        "categorical_columns = [\"Gender\", \"Medical_History\", \"Drug_Name\", \"Side_Effects\", \"Disease_Type\", \"Genetic_Marker\", \"Response_to_Treatment\"]\n",
        "\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    dataset[col] = le.fit_transform(dataset[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Selecting features and target variables\n",
        "# Selecting features and target variables\n",
        "import joblib\n",
        "\n",
        "# Selecting features (Ensure \"Response_to_Treatment\" is excluded)\n",
        "X = dataset.drop(columns=[\"Patient_ID\", \"Response_to_Treatment\"]).values\n",
        "y = dataset[\"Response_to_Treatment\"].values\n",
        "\n",
        "# Save feature names (to ensure consistency during prediction)\n",
        "feature_names = list(dataset.drop(columns=[\"Patient_ID\", \"Response_to_Treatment\"]).columns)\n",
        "joblib.dump(feature_names, \"feature_names.pkl\")  # Save feature names\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Save the trained scaler\n",
        "joblib.dump(scaler, \"scalers.pkl\")\n",
        "print(\"Scaler and feature names saved successfully!\")\n",
        "\n",
        "\n",
        "\n",
        "# Reshape for CNN input (assuming 1D features per patient)\n",
        "X = np.expand_dims(X, axis=2)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X.shape[1], 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.2),\n",
        "    \n",
        "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.3),\n",
        "    \n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
        "\n",
        "# Save the model\n",
        "model.save(\"cnn_drug_discovery_model.h5\")\n",
        "print(\"Model saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model, scaler, and feature names loaded successfully!\n",
            "Expected Features from Training: ['Age', 'Gender', 'Medical_History', 'Drug_Name', 'Dosage_mg', 'Treatment_Duration_days', 'Effectiveness_%', 'Side_Effects', 'Disease_Type', 'Genetic_Marker', 'Success_Rate_%']\n",
            "Warning: Missing feature 'Success_Rate_%' in input data. Assigning default value 0.\n",
            "1/1 [==============================] - 0s 132ms/step\n",
            "Predicted Drug Effectiveness: 69.87%\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load model, scaler, and feature names\n",
        "model = load_model(\"cnn_drug_discovery_model.h5\")\n",
        "scaler = joblib.load(\"scalers.pkl\")\n",
        "expected_features = joblib.load(\"feature_names.pkl\")  # Load expected feature names\n",
        "print(\"Model, scaler, and feature names loaded successfully!\")\n",
        "\n",
        "# Print expected features for debugging\n",
        "print(\"Expected Features from Training:\", expected_features)\n",
        "\n",
        "# Define label encoders\n",
        "label_encoders = {\n",
        "    \"Gender\": LabelEncoder().fit([\"Male\", \"Female\"]),\n",
        "    \"Medical_History\": LabelEncoder().fit([\"Diabetes\", \"Hypertension\", \"Cancer\", \"None\"]),\n",
        "    \"Drug_Name\": LabelEncoder().fit([\"DrugA\", \"DrugB\", \"DrugC\", \"DrugD\"]),\n",
        "    \"Side_Effects\": LabelEncoder().fit([\"None\", \"Nausea\", \"Dizziness\", \"Fatigue\"]),\n",
        "    \"Disease_Type\": LabelEncoder().fit([\"Lung Cancer\", \"Breast Cancer\", \"Diabetes\", \"Heart Disease\"]),\n",
        "    \"Genetic_Marker\": LabelEncoder().fit([\"MarkerA\", \"MarkerB\", \"MarkerC\", \"MarkerD\"])\n",
        "}\n",
        "\n",
        "# Example input values (Ensure all expected features are included)\n",
        "input_data = {\n",
        "    \"Age\": 45,\n",
        "    \"Gender\": \"Male\",\n",
        "    \"Medical_History\": \"Diabetes\",\n",
        "    \"Drug_Name\": \"DrugA\",\n",
        "    \"Dosage_mg\": 900,\n",
        "    \"Treatment_Duration_days\": 10,\n",
        "    \"Effectiveness_%\": 95.4,\n",
        "    \"Side_Effects\": \"Nausea\",\n",
        "    \"Disease_Type\": \"Lung Cancer\",\n",
        "    \"Genetic_Marker\": \"MarkerB\"\n",
        "}\n",
        "\n",
        "# Encode categorical values\n",
        "for key in label_encoders:\n",
        "    if key in input_data:\n",
        "        input_data[key] = label_encoders[key].transform([input_data[key]])[0]\n",
        "\n",
        "# Ensure input_data has all expected features\n",
        "for feature in expected_features:\n",
        "    if feature not in input_data:\n",
        "        print(f\"Warning: Missing feature '{feature}' in input data. Assigning default value 0.\")\n",
        "        input_data[feature] = 0  # Default value (adjust if needed)\n",
        "\n",
        "# Convert input data to NumPy array in correct order\n",
        "input_array = np.array([input_data[feature] for feature in expected_features]).reshape(1, -1)\n",
        "\n",
        "# Verify feature count consistency\n",
        "if input_array.shape[1] != scaler.n_features_in_:\n",
        "    raise ValueError(f\"Feature mismatch: Expected {scaler.n_features_in_}, but got {input_array.shape[1]}.\")\n",
        "\n",
        "# Normalize input using the pre-trained scaler\n",
        "input_array = scaler.transform(input_array)\n",
        "\n",
        "# Reshape for CNN input\n",
        "input_array = np.expand_dims(input_array, axis=2)\n",
        "\n",
        "# Make prediction\n",
        "prediction = model.predict(input_array)\n",
        "effectiveness_score = prediction[0][0] * 100  # Convert to percentage\n",
        "\n",
        "print(f\"Predicted Drug Effectiveness: {effectiveness_score:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
